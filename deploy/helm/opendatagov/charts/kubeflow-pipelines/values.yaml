# Default values for kubeflow-pipelines chart

# Global settings
global:
  profile: dev
  gpu:
    enabled: false

# Kubeflow Pipelines API Server
apiServer:
  enabled: true
  replicaCount: 1
  image:
    repository: gcr.io/ml-pipeline/api-server
    tag: "2.0.5"
    pullPolicy: IfNotPresent

  service:
    type: ClusterIP
    port: 8888
    targetPort: 8888

  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 1
      memory: 2Gi

  # Database configuration (ML Metadata + Pipeline metadata)
  database:
    host: ""  # Auto-configured to shared PostgreSQL
    port: 5432
    name: kubeflow
    existingSecret: ""

  # Object storage for artifacts (MinIO/S3)
  objectStore:
    type: minio
    host: ""  # Auto-configured to MinIO
    port: 9000
    bucket: kubeflow-artifacts
    existingSecret: ""

# Persistence Agent - saves pipeline runs to database
persistenceAgent:
  enabled: true
  image:
    repository: gcr.io/ml-pipeline/persistenceagent
    tag: "2.0.5"
  resources:
    requests:
      cpu: 250m
      memory: 512Mi
    limits:
      cpu: 500m
      memory: 1Gi

# Scheduled Workflow Controller
scheduledWorkflow:
  enabled: true
  image:
    repository: gcr.io/ml-pipeline/scheduledworkflow
    tag: "2.0.5"
  resources:
    requests:
      cpu: 250m
      memory: 512Mi
    limits:
      cpu: 500m
      memory: 1Gi

# ML Metadata (MLMD) - artifact tracking
mlMetadata:
  enabled: true
  image:
    repository: gcr.io/tfx-oss-public/ml_metadata_store_server
    tag: "1.14.0"
  service:
    type: ClusterIP
    port: 8080
  resources:
    requests:
      cpu: 250m
      memory: 512Mi
    limits:
      cpu: 500m
      memory: 1Gi

# Kubeflow Pipelines UI
ui:
  enabled: true
  replicaCount: 1
  image:
    repository: gcr.io/ml-pipeline/frontend
    tag: "2.0.5"
  service:
    type: ClusterIP
    port: 80
    targetPort: 3000
  resources:
    requests:
      cpu: 250m
      memory: 512Mi
    limits:
      cpu: 500m
      memory: 1Gi

# Argo Workflows (execution engine)
argoWorkflows:
  enabled: true
  controller:
    replicas: 1
    resources:
      requests:
        cpu: 500m
        memory: 512Mi
      limits:
        cpu: 1
        memory: 1Gi
  server:
    enabled: true
    replicas: 1
    resources:
      requests:
        cpu: 250m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 512Mi
  # Workflow executor configuration
  executor:
    resources:
      requests:
        cpu: 100m
        memory: 64Mi
      limits:
        cpu: 500m
        memory: 512Mi

# GPU configuration for training workloads
gpu:
  enabled: false
  nodeSelector:
    accelerator: nvidia-gpu
  tolerations:
    - key: nvidia.com/gpu
      operator: Exists
      effect: NoSchedule
  resourceName: nvidia.com/gpu

# Governance integration with OpenDataGov
governance:
  enabled: false  # Disabled in dev
  qualityGateUrl: "http://quality-gate:8003"
  minDQScore: 0.95  # Minimum DQ score for Gold layer
  governanceEngineUrl: "http://governance-engine:8000"

# Service Account
serviceAccount:
  create: true
  name: ""
  annotations: {}

# Pod Security Context
podSecurityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 1000
  seccompProfile:
    type: RuntimeDefault

securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop:
      - ALL
  readOnlyRootFilesystem: false  # Kubeflow needs write access

# Autoscaling (for medium/large profiles)
autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 5
  targetCPUUtilizationPercentage: 75

# Monitoring
monitoring:
  enabled: true
  serviceMonitor:
    enabled: false
    interval: 30s

# Network policies
networkPolicy:
  enabled: false

# Node selector
nodeSelector: {}

# Tolerations
tolerations: []

# Affinity
affinity: {}

# Extra environment variables
extraEnv: []

# Extra volumes
extraVolumes: []

# Extra volume mounts
extraVolumeMounts: []
